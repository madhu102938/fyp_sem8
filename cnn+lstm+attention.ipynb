{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y0TyzxthhRch"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, ConvLSTM3D, Conv3D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling3D, Concatenate, TimeDistributed, MaxPooling3D, AveragePooling3D, GlobalMaxPooling3D, LSTM, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "devices = tf.config.list_physical_devices()\n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "def returning_pkl_file_data(path : str):\n",
    "    with open(path, 'rb') as f:\n",
    "        temp = pkl.load(f)\n",
    "    return temp\n",
    "\n",
    "mci_func = returning_pkl_file_data(r\"feature_extraction/MCI_func_52_79_95_79_197.pkl\")\n",
    "mci_struct = returning_pkl_file_data(r'feature_extraction/MCI_struct_cat_52_169_205_169.pkl')\n",
    "cn_func = returning_pkl_file_data(r'feature_extraction/CN_func_42_79_95_79_197.pkl')\n",
    "cn_struct = returning_pkl_file_data(r'feature_extraction/CN_struct_cat_42_169_205_169.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 79, 95, 79, 197)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_data = np.concat((mci_func, cn_func), axis=0, dtype=np.float16)\n",
    "func_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 169, 205, 169)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_data = np.concat((mci_struct, cn_struct), axis=0, dtype=np.float16)\n",
    "struct_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = np.concat((np.zeros((len(mci_func),)), np.ones((len(cn_func),))))\n",
    "all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94, 79, 95, 79, 197, 1), (94, 169, 205, 169, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_data = np.expand_dims(func_data, axis=len(func_data.shape))\n",
    "struct_data = np.expand_dims(struct_data, axis=len(struct_data.shape))\n",
    "\n",
    "func_data.shape, struct_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create memory-efficient dataset using generator\n",
    "class BrainDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, func_data, struct_data, labels, batch_size=4):\n",
    "        self.func_data = func_data\n",
    "        self.struct_data = struct_data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(func_data))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.func_data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        return (\n",
    "            {\n",
    "                'func': self.func_data[batch_indices],\n",
    "                'struct': self.struct_data[batch_indices]\n",
    "            },\n",
    "            self.labels[batch_indices]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split indices to avoid data duplication\n",
    "indices = np.arange(len(func_data))\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create memory-mapped datasets\n",
    "train_generator = BrainDataGenerator(\n",
    "    func_data[train_idx], \n",
    "    struct_data[train_idx], \n",
    "    all_labels[train_idx]\n",
    ")\n",
    "\n",
    "test_generator = BrainDataGenerator(\n",
    "    func_data[test_idx], \n",
    "    struct_data[test_idx], \n",
    "    all_labels[test_idx],\n",
    "    batch_size=len(test_idx)  # Full batch for testing\n",
    ")\n",
    "\n",
    "# 4. Convert to tf.data.Dataset with optimized pipeline\n",
    "def create_tf_dataset(generator):\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        lambda: generator,\n",
    "        output_signature=(\n",
    "            {\n",
    "                'func': tf.TensorSpec(shape=(None, 79, 95, 79, 197, 1), dtype=tf.float16),\n",
    "                'struct': tf.TensorSpec(shape=(None, 169, 205, 169, 1), dtype=tf.float16)\n",
    "            },\n",
    "            tf.TensorSpec(shape=(None,), dtype=tf.float16)\n",
    "        )\n",
    "    ).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = create_tf_dataset(train_generator)\n",
    "test_dataset = create_tf_dataset(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "id": "qc5Wcgt0et5F",
    "outputId": "23ec5b44-23f7-4990-e140-155fd7a4feb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"Combined_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " func (InputLayer)           [(None, 79, 95, 79, 197, 1   0         []                            \n",
      "                             )]                                                                   \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)           (None, 197, 79, 95, 79, 1)   0         ['func[0][0]']                \n",
      "                                                                                                  \n",
      " struct (InputLayer)         [(None, 169, 205, 169, 1)]   0         []                            \n",
      "                                                                                                  \n",
      " time_distributed_5 (TimeDi  (None, 197, 79, 95, 79, 32   896       ['lambda_1[0][0]']            \n",
      " stributed)                  )                                                                    \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)           (None, 167, 203, 167, 32)    896       ['struct[0][0]']              \n",
      "                                                                                                  \n",
      " time_distributed_6 (TimeDi  (None, 197, 39, 47, 39, 32   0         ['time_distributed_5[0][0]']  \n",
      " stributed)                  )                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 167, 203, 167, 32)    128       ['conv3d_4[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " time_distributed_7 (TimeDi  (None, 197, 39, 47, 39, 64   55360     ['time_distributed_6[0][0]']  \n",
      " stributed)                  )                                                                    \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)           (None, 165, 201, 165, 32)    27680     ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " time_distributed_8 (TimeDi  (None, 197, 64)              0         ['time_distributed_7[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 165, 201, 165, 32)    128       ['conv3d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 12608)                0         ['time_distributed_8[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling3d_3  (None, 32)                   0         ['batch_normalization_1[0][0]'\n",
      "  (GlobalAveragePooling3D)                                          ]                             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  1613952   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 128)                  4224      ['global_average_pooling3d_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 256)                  0         ['dense[0][0]',               \n",
      "                                                                     'dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  32896     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 128)                  0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    129       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1736289 (6.62 MB)\n",
      "Trainable params: 1736161 (6.62 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# --- fMRI Model (ConvLSTM) ---\n",
    "def build_fmri_model():\n",
    "    fmri_input = Input(shape=(79, 95, 79, 197, 1), name=\"func\", dtype=tf.float16)\n",
    "    x = Lambda(lambda x: tf.transpose(x, perm=[0, 4, 1, 2, 3, 5]))(fmri_input)\n",
    "    # Apply Conv3D independently to each time step\n",
    "    x = TimeDistributed(Conv3D(32, (3,3,3), padding=\"same\", activation=\"relu\"))(x)\n",
    "    x = TimeDistributed(MaxPooling3D(2))(x)  # Downsample spatial dimensions\n",
    "    x = TimeDistributed(Conv3D(64, (3,3,3), padding=\"same\", activation=\"relu\"))(x)\n",
    "    x = TimeDistributed(GlobalAveragePooling3D())(x)  # Shape: (batch, time=197, 64)\n",
    "    # Temporal modeling with LSTM\n",
    "    x = LSTM(128)(x)  # Output shape: (batch, 128)\n",
    "    return Model(inputs=fmri_input, outputs=x, name=\"fMRI_Model\")\n",
    "\n",
    "# --- sMRI Model (3D CNN) ---\n",
    "def build_smri_model():\n",
    "    smri_input = Input(shape=(169, 205, 169, 1), name=\"struct\", dtype=tf.float16)\n",
    "\n",
    "    y = Conv3D(filters=32, kernel_size=(3,3,3), activation=\"relu\", padding=\"valid\")(smri_input)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Conv3D(filters=32, kernel_size=(3,3,3), activation=\"relu\", padding=\"valid\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    y = GlobalAveragePooling3D()(y)\n",
    "    y = Dense(128, activation=\"relu\")(y)\n",
    "\n",
    "    return Model(inputs=smri_input, outputs=y, name=\"sMRI_Model\")\n",
    "\n",
    "# --- Combine fMRI & sMRI Models ---\n",
    "def build_combined_model():\n",
    "    fmri_model = build_fmri_model()\n",
    "    smri_model = build_smri_model()\n",
    "\n",
    "    combined = Concatenate()([fmri_model.output, smri_model.output])\n",
    "    combined = Dense(128, activation=\"relu\")(combined)\n",
    "    combined = Dropout(0.5)(combined)\n",
    "    output = Dense(1, activation=\"sigmoid\")(combined)\n",
    "\n",
    "    model = Model(inputs=[fmri_model.input, smri_model.input], outputs=output, name=\"Combined_Model\")\n",
    "    return model\n",
    "\n",
    "# Build & Compile Model\n",
    "model = build_combined_model()\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w5DQyVy7gobu",
    "outputId": "dcffe9f0-8f95-4f7b-b800-8496be868ac7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 5, 4, 4, 4, 1), (100, 10, 10, 10, 1), (100,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_data = np.random.rand(100, 5, 4, 4, 4, 1)\n",
    "struct_data = np.random.rand(100, 10, 10, 10, 1)\n",
    "all_labels = np.random.randint(0, 2, size=(100,))\n",
    "func_data.shape, struct_data.shape, all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JAaAp4ICh_Zu"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5HemPPf5icUx",
    "outputId": "494eb634-c62c-4710-f3a0-7bbeb83046e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 5, 4, 4, 4, 1),\n",
       " (20, 5, 4, 4, 4, 1),\n",
       " (80, 10, 10, 10, 1),\n",
       " (20, 10, 10, 10, 1),\n",
       " (80,),\n",
       " (20,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fmri, val_fmri, train_smri, val_smri, train_labels, val_labels = train_test_split(fmri_data, smri_data, labels, test_size=0.2, random_state=42)\n",
    "train_fmri.shape, val_fmri.shape, train_smri.shape, val_smri.shape, train_labels.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "8_aofj-zhnaY",
    "outputId": "92860580-1622-4cef-de33-f8dc36a85992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nTypeError: `generator` yielded an element of shape (4, 5, 4, 4, 4, 1) where an element of shape (None, 79, 95, 79, 197, 1) was expected.\nTraceback (most recent call last):\n\n  File \"c:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"c:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (4, 5, 4, 4, 4, 1) where an element of shape (None, 79, 95, 79, 197, 1) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_3126]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      2\u001b[0m     train_dataset,\n\u001b[0;32m      3\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mtest_dataset,\n\u001b[0;32m      4\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      5\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_generator),\n\u001b[0;32m      6\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nTypeError: `generator` yielded an element of shape (4, 5, 4, 4, 4, 1) where an element of shape (None, 79, 95, 79, 197, 1) was expected.\nTraceback (most recent call last):\n\n  File \"c:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"c:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (4, 5, 4, 4, 4, 1) where an element of shape (None, 79, 95, 79, 197, 1) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_3126]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOfh24h4iplQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
