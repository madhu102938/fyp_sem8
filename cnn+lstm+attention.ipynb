{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y0TyzxthhRch"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, ConvLSTM3D, Conv3D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling3D, Concatenate, TimeDistributed, MaxPooling3D, AveragePooling3D, GlobalMaxPooling3D, LSTM, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "devices = tf.config.list_physical_devices()\n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "def returning_pkl_file_data(path : str):\n",
    "    with open(path, 'rb') as f:\n",
    "        temp = pkl.load(f)\n",
    "    return temp\n",
    "\n",
    "mci_func = returning_pkl_file_data(r\"feature_extraction/MCI_func_52_79_95_79_197.pkl\")\n",
    "mci_struct = returning_pkl_file_data(r'feature_extraction/MCI_struct_cat_52_169_205_169.pkl')\n",
    "cn_func = returning_pkl_file_data(r'feature_extraction/CN_func_42_79_95_79_197.pkl')\n",
    "cn_struct = returning_pkl_file_data(r'feature_extraction/CN_struct_cat_42_169_205_169.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 79, 95, 79, 197)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_data = np.concat((mci_func, cn_func), axis=0, dtype=np.float16)\n",
    "func_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 169, 205, 169)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_data = np.concat((mci_struct, cn_struct), axis=0, dtype=np.float16)\n",
    "struct_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = np.concat((np.zeros((len(mci_func),)), np.ones((len(cn_func),))))\n",
    "all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94, 79, 95, 79, 197, 1), (94, 169, 205, 169, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_data = np.expand_dims(func_data, axis=len(func_data.shape))\n",
    "struct_data = np.expand_dims(struct_data, axis=len(struct_data.shape))\n",
    "\n",
    "func_data.shape, struct_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create memory-efficient dataset using generator\n",
    "class BrainDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, func_data, struct_data, labels, batch_size=4):\n",
    "        self.func_data = func_data\n",
    "        self.struct_data = struct_data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(func_data))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.func_data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        return (\n",
    "            {\n",
    "                'func': self.func_data[batch_indices],\n",
    "                'struct': self.struct_data[batch_indices]\n",
    "            },\n",
    "            self.labels[batch_indices]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split indices to avoid data duplication\n",
    "indices = np.arange(len(func_data))\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create memory-mapped datasets\n",
    "train_generator = BrainDataGenerator(\n",
    "    func_data[train_idx], \n",
    "    struct_data[train_idx], \n",
    "    all_labels[train_idx]\n",
    ")\n",
    "\n",
    "test_generator = BrainDataGenerator(\n",
    "    func_data[test_idx], \n",
    "    struct_data[test_idx], \n",
    "    all_labels[test_idx],\n",
    "    batch_size=len(test_idx)  # Full batch for testing\n",
    ")\n",
    "\n",
    "# 4. Convert to tf.data.Dataset with optimized pipeline\n",
    "def create_tf_dataset(generator, training=True):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: generator,\n",
    "        output_signature=(\n",
    "            {\n",
    "                'func': tf.TensorSpec(shape=(None, *func_data.shape[1:]), dtype=tf.float16),\n",
    "                'struct': tf.TensorSpec(shape=(None, *struct_data.shape[1:]), dtype=tf.float16)\n",
    "            },\n",
    "            tf.TensorSpec(shape=(None,), dtype=tf.float16)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if training:\n",
    "        dataset = dataset.repeat()  # Infinite repetition for training\n",
    "        dataset = dataset.shuffle(100)\n",
    "        \n",
    "    dataset = dataset.cache().prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = create_tf_dataset(train_generator)\n",
    "test_dataset = create_tf_dataset(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "id": "qc5Wcgt0et5F",
    "outputId": "23ec5b44-23f7-4990-e140-155fd7a4feb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Combined_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " func (InputLayer)           [(None, 5, 4, 4, 4, 1)]      0         []                            \n",
      "                                                                                                  \n",
      " struct (InputLayer)         [(None, 10, 10, 10, 1)]      0         []                            \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)           (None, 4, 5, 4, 4, 1)        0         ['func[0][0]']                \n",
      "                                                                                                  \n",
      " conv3d_12 (Conv3D)          (None, 8, 8, 8, 32)          896       ['struct[0][0]']              \n",
      "                                                                                                  \n",
      " time_distributed_13 (TimeD  (None, 4, 5, 4, 4, 32)       896       ['lambda_3[0][0]']            \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 8, 8, 8, 32)          128       ['conv3d_12[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " time_distributed_14 (TimeD  (None, 4, 2, 2, 2, 32)       0         ['time_distributed_13[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " conv3d_13 (Conv3D)          (None, 6, 6, 6, 32)          27680     ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " time_distributed_15 (TimeD  (None, 4, 2, 2, 2, 64)       55360     ['time_distributed_14[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 6, 6, 6, 32)          128       ['conv3d_13[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " time_distributed_16 (TimeD  (None, 4, 64)                0         ['time_distributed_15[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " global_average_pooling3d_7  (None, 32)                   0         ['batch_normalization_5[0][0]'\n",
      "  (GlobalAveragePooling3D)                                          ]                             \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 128)                  98816     ['time_distributed_16[0][0]'] \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 128)                  4224      ['global_average_pooling3d_7[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 256)                  0         ['lstm_1[0][0]',              \n",
      " )                                                                   'dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 128)                  32896     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 128)                  0         ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 1)                    129       ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 221153 (863.88 KB)\n",
      "Trainable params: 221025 (863.38 KB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# --- fMRI Model (ConvLSTM) ---\n",
    "def build_fmri_model():\n",
    "    fmri_input = Input(shape=func_data.shape[1:], name=\"func\", dtype=tf.float16)\n",
    "    x = Lambda(lambda x: tf.transpose(x, perm=[0, 4, 1, 2, 3, 5]))(fmri_input)\n",
    "    # Apply Conv3D independently to each time step\n",
    "    x = TimeDistributed(Conv3D(32, (3,3,3), padding=\"same\", activation=\"relu\"))(x)\n",
    "    x = TimeDistributed(MaxPooling3D(2))(x)  # Downsample spatial dimensions\n",
    "    x = TimeDistributed(Conv3D(64, (3,3,3), padding=\"same\", activation=\"relu\"))(x)\n",
    "    x = TimeDistributed(GlobalAveragePooling3D())(x)  # Shape: (batch, time=197, 64)\n",
    "    # Temporal modeling with LSTM\n",
    "    x = LSTM(128)(x)  # Output shape: (batch, 128)\n",
    "    return Model(inputs=fmri_input, outputs=x, name=\"fMRI_Model\")\n",
    "\n",
    "# --- sMRI Model (3D CNN) ---\n",
    "def build_smri_model():\n",
    "    smri_input = Input(shape=struct_data.shape[1:], name=\"struct\", dtype=tf.float16)\n",
    "\n",
    "    y = Conv3D(filters=32, kernel_size=(3,3,3), activation=\"relu\", padding=\"valid\")(smri_input)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Conv3D(filters=32, kernel_size=(3,3,3), activation=\"relu\", padding=\"valid\")(y)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    y = GlobalAveragePooling3D()(y)\n",
    "    y = Dense(128, activation=\"relu\")(y)\n",
    "\n",
    "    return Model(inputs=smri_input, outputs=y, name=\"sMRI_Model\")\n",
    "\n",
    "# --- Combine fMRI & sMRI Models ---\n",
    "def build_combined_model():\n",
    "    fmri_model = build_fmri_model()\n",
    "    smri_model = build_smri_model()\n",
    "\n",
    "    combined = Concatenate()([fmri_model.output, smri_model.output])\n",
    "    combined = Dense(128, activation=\"relu\")(combined)\n",
    "    combined = Dropout(0.5)(combined)\n",
    "    output = Dense(1, activation=\"sigmoid\")(combined)\n",
    "\n",
    "    model = Model(inputs=[fmri_model.input, smri_model.input], outputs=output, name=\"Combined_Model\")\n",
    "    return model\n",
    "\n",
    "# Build & Compile Model\n",
    "model = build_combined_model()\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w5DQyVy7gobu",
    "outputId": "dcffe9f0-8f95-4f7b-b800-8496be868ac7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 5, 4, 4, 4, 1), (100, 10, 10, 10, 1), (100,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_data = np.random.rand(100, 5, 4, 4, 4, 1)\n",
    "struct_data = np.random.rand(100, 10, 10, 10, 1)\n",
    "all_labels = np.random.randint(0, 2, size=(100,))\n",
    "func_data.shape, struct_data.shape, all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JAaAp4ICh_Zu"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5HemPPf5icUx",
    "outputId": "494eb634-c62c-4710-f3a0-7bbeb83046e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 5, 4, 4, 4, 1),\n",
       " (20, 5, 4, 4, 4, 1),\n",
       " (80, 10, 10, 10, 1),\n",
       " (20, 10, 10, 10, 1),\n",
       " (80,),\n",
       " (20,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fmri, val_fmri, train_smri, val_smri, train_labels, val_labels = train_test_split(fmri_data, smri_data, labels, test_size=0.2, random_state=42)\n",
    "train_fmri.shape, val_fmri.shape, train_smri.shape, val_smri.shape, train_labels.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "8_aofj-zhnaY",
    "outputId": "92860580-1622-4cef-de33-f8dc36a85992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 4s 37ms/step - loss: 0.6834 - accuracy: 0.5500 - val_loss: 0.6883 - val_accuracy: 0.5500\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6593 - accuracy: 0.6375 - val_loss: 0.7028 - val_accuracy: 0.5500\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.5766 - accuracy: 0.7875 - val_loss: 0.7324 - val_accuracy: 0.5500\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.4114 - accuracy: 0.8875 - val_loss: 0.8189 - val_accuracy: 0.5500\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.1882 - accuracy: 0.9625 - val_loss: 0.9710 - val_accuracy: 0.5500\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.1398 - accuracy: 0.9500 - val_loss: 2.2942 - val_accuracy: 0.5500\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.2042 - accuracy: 0.9125 - val_loss: 0.8912 - val_accuracy: 0.5500\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.9432 - val_accuracy: 0.4500\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.8214 - val_accuracy: 0.5500\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.0660 - accuracy: 0.9875 - val_loss: 0.8314 - val_accuracy: 0.5500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
