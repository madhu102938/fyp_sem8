{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a1d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "971c2aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 19:44:46.135635: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-07 19:44:46.188488: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-07 19:44:46.188547: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-07 19:44:46.188590: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-07 19:44:46.199035: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-07 19:44:47.188575: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers, Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2841885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "devices = tf.config.list_physical_devices()\n",
    "print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e246f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80939d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_MCI_Features_file_path = r'./feature_extraction/MCI_func_features.pkl'\n",
    "with open(pickle_MCI_Features_file_path, 'rb') as file:\n",
    "    MCI_funct_features = pickle.load(file)\n",
    "MCI_funct_features.shape\n",
    "MCI_funct_features = np.array(MCI_funct_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c813465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 13456)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCI_funct_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee3a6fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_MCI_Features_file_path = r'feature_extraction/cat12_MCI_structural_features.pkl'\n",
    "with open(pickle_MCI_Features_file_path, 'rb') as file:\n",
    "    MCI_Struct_features = pickle.load(file)\n",
    "MCI_Struct_features.shape\n",
    "MCI_Struct_features = np.array(MCI_Struct_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9886dee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 169, 205, 169)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCI_Struct_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53ad34c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structural_features loaded successfully!\n",
      "Shape of loaded array: (40, 169, 205, 169)\n"
     ]
    }
   ],
   "source": [
    "# Define the same file path\n",
    "file_path = r'feature_extraction/cat12_AD_structural_features.pkl'\n",
    "\n",
    "# Load the NumPy array from the file\n",
    "with open(file_path, \"rb\") as file:  # 'rb' means read binary\n",
    "    AD_struct_features = pickle.load(file)\n",
    "\n",
    "print(\"structural_features loaded successfully!\")\n",
    "print(\"Shape of loaded array:\", AD_struct_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "959837d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 13456)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_AD_Features_file_path = r\"feature_extraction/AD_func_features.pkl\"\n",
    "with open(pickle_AD_Features_file_path, 'rb') as file:\n",
    "    AD_funct_features = pickle.load(file)\n",
    "AD_funct_features = np.array(AD_funct_features)\n",
    "AD_funct_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "697e6519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structural_features loaded successfully!\n",
      "Shape of loaded array: (30, 169, 205, 169)\n"
     ]
    }
   ],
   "source": [
    "# Define the same file path\n",
    "file_path = r'feature_extraction/cat12_CN_structural_features.pkl'\n",
    "\n",
    "# Load the NumPy array from the file\n",
    "with open(file_path, \"rb\") as file:  # 'rb' means read binary\n",
    "    CN_struct_features = pickle.load(file)\n",
    "\n",
    "print(\"structural_features loaded successfully!\")\n",
    "print(\"Shape of loaded array:\", CN_struct_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9217afde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 13456)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_AD_Features_file_path = r\"feature_extraction/CN_func_features.pkl\"\n",
    "with open(pickle_AD_Features_file_path, 'rb') as file:\n",
    "    CN_funct_features = pickle.load(file)\n",
    "CN_funct_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4526fd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52, 13456), (52, 169, 205, 169))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCI_funct_features.shape, MCI_Struct_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed6ff037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 13456), (40, 169, 205, 169))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AD_funct_features.shape, AD_struct_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ac8adef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 13456), (30, 169, 205, 169))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CN_funct_features.shape, CN_struct_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4e4b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Shapes\n",
    "AD_Struct_features = AD_struct_features\n",
    "# Labels\n",
    "MCI_labels = np.zeros(MCI_funct_features.shape[0])  # Label 0 for MCI\n",
    "AD_labels = np.ones(AD_funct_features.shape[0])    # Label 1 for AD\n",
    "CN_labels = np.array([2]*CN_funct_features.shape[0])\n",
    "\n",
    "# Combine functional and structural features\n",
    "funct_features = np.vstack((MCI_funct_features, AD_funct_features, CN_funct_features))\n",
    "struct_features = np.vstack((MCI_Struct_features, AD_Struct_features, CN_struct_features))\n",
    "labels = np.hstack((MCI_labels, AD_labels, CN_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cce47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_features = np.expand_dims(struct_features, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "424a6930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 116, 116, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funct_features = funct_features.reshape(-1, 116, 116)\n",
    "funct_features = np.expand_dims(funct_features, axis=-1)\n",
    "funct_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af957b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "funct_features = np.random.rand(15, 116, 116, 1)\n",
    "struct_features = np.random.rand(15, 169, 205, 169)\n",
    "labels = np.array([0]*5 + [1]*5 + [2]*5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99402c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "794478e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train_3d, X_test_3d, X_train_2d, X_test_2d, y_train, y_test = train_test_split(\n",
    "    struct_features,\n",
    "    funct_features,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "498c87b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator labels (real images are labeled as 1)\n",
    "real_labels_train = np.ones((X_train_3d.shape[0], 1))\n",
    "real_labels_test = np.ones((X_test_3d.shape[0], 1))\n",
    "\n",
    "# For simplicity, use real labels for reconstructed images\n",
    "disc_targets_3d_train = real_labels_train\n",
    "disc_targets_2d_train = real_labels_train\n",
    "\n",
    "disc_targets_3d_test = real_labels_test\n",
    "disc_targets_2d_test = real_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aec97d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "def build_encoder_3d_2d(input_shape):\n",
    "    inputs = Input(shape=input_shape) # 169x205 x169 (input, 169 channels)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='gelu', padding='valid')(inputs) # 166×203 ×32\n",
    "    x = layers.MaxPooling2D((2, 2))(x) # 83×101×83 x32\n",
    "    x = layers.Conv2D(64, (3, 3), activation='gelu', padding='valid')(x) # 81×99 x64\n",
    "    x = layers.MaxPooling2D((2, 2))(x) # 40×49×40 x64\n",
    "    x = layers.Conv2D(128, (3, 3), activation='gelu', padding='valid')(x) # 38×47 x128\n",
    "    x = layers.Flatten()(x)\n",
    "    latent = layers.Dense(256, activation='gelu', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "    encoder = Model(inputs, latent, name='encoder_3d')\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "555b5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder_2d(input_shape):\n",
    "    inputs = Input(shape=input_shape) # 116x116 x1\n",
    "    x = layers.Conv2D(32, (3, 3), activation='gelu', padding='valid')(inputs) # 114x114 x32\n",
    "    x = layers.MaxPooling2D((2, 2))(x) # 57x57 x32\n",
    "    x = layers.Conv2D(64, (3, 3), activation='gelu', padding='valid')(x) # 55x55 x64\n",
    "    x = layers.MaxPooling2D((2, 2))(x) # 27x27 x64\n",
    "    x = layers.Conv2D(128, (3, 3), activation='gelu', padding='valid')(x) # 25x25 x128\n",
    "    x = layers.Flatten()(x)\n",
    "    latent = layers.Dense(256, activation='gelu', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "    encoder = Model(inputs, latent, name='encoder_2d')\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0084b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder_3d_2d(latent_dim, output_shape):\n",
    "    # output_shape: (height, width, channels) - Original 2D data shape with high number of channels\n",
    "    height, width, channels = output_shape[0], output_shape[1], output_shape[2]\n",
    "    \n",
    "    latent_inputs = Input(shape=(latent_dim,))\n",
    "    \n",
    "    # Define the dimensions to reshape the latent vector\n",
    "    reshape_height = height // 8\n",
    "    reshape_width = width // 8\n",
    "    reshape_filters = 128  # Number of filters\n",
    "    \n",
    "    x = layers.Dense(reshape_height * reshape_width * reshape_filters, activation='gelu')(latent_inputs)\n",
    "    x = layers.Reshape((reshape_height, reshape_width, reshape_filters))(x)\n",
    "    \n",
    "    # Upsample spatial dimensions\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same', activation='gelu')(x)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same', activation='gelu')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), strides=2, padding='same', activation='gelu')(x)\n",
    "    \n",
    "    # Final layer to match the number of channels\n",
    "    x = layers.ZeroPadding2D(padding=((0, 1), (0, 5)))(x)\n",
    "    outputs = layers.Conv2DTranspose(channels, (3, 3), padding='same', activation='sigmoid')(x)\n",
    "    assert outputs.shape[1:] == output_shape, f\"Expected output shape {output_shape} but got {outputs.shape[1:]}\"\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder_3d')\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "182bf318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder_2d(latent_dim, output_shape):\n",
    "    latent_inputs = Input(shape=(latent_dim,))\n",
    "    x = layers.Dense((output_shape[0]//4)*(output_shape[1]//4)*64, activation='gelu')(latent_inputs)\n",
    "    x = layers.Reshape((output_shape[0]//4, output_shape[1]//4, 64))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), strides=2, padding='valid', activation='gelu')(x)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), strides=2, padding='valid', activation='gelu')(x)\n",
    "    x = layers.Conv2DTranspose(1, (3, 3), padding='valid', activation='sigmoid')(x)\n",
    "    outputs = layers.Cropping2D(cropping=((2, 3), (2, 3)))(x) \n",
    "\n",
    "    assert outputs.shape[1:-1] == output_shape, f\"Output shape {outputs.shape[1:-1]} does not match expected shape {output_shape}\"\n",
    "\n",
    "\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder_2d')\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa84d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_3d_2d(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='gelu')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='gelu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    discriminator = Model(inputs, outputs, name='discriminator_3d')\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b00762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_2d(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='gelu')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='gelu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    discriminator = Model(inputs, outputs, name='discriminator_2d')\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "947f1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(input_dim, num_classes):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    # x = layers.Dense(256, activation='gelu')(inputs)\n",
    "    x = layers.Dense(128, activation='gelu', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    classifier = Model(inputs, outputs, name='classifier')\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ffb776c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 19:45:22.604969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45738 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:4b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Input shapes\n",
    "input_shape_3d = (169, 205, 169)\n",
    "input_shape_2d = (116, 116, 1)\n",
    "latent_dim = 256\n",
    "num_classes = 3\n",
    "\n",
    "# Build models\n",
    "encoder_3d = build_encoder_3d_2d(input_shape_3d)\n",
    "encoder_2d = build_encoder_2d(input_shape_2d)\n",
    "decoder_3d = build_decoder_3d_2d(latent_dim, input_shape_3d)\n",
    "decoder_2d = build_decoder_2d(latent_dim, input_shape_2d[:-1])\n",
    "discriminator_3d = build_discriminator_3d_2d(input_shape_3d)\n",
    "discriminator_2d = build_discriminator_2d(input_shape_2d)\n",
    "# Build classifier that accepts concatenated latent vectors\n",
    "classifier = build_classifier(latent_dim * 2, num_classes)\n",
    "\n",
    "# Inputs\n",
    "input_3d = Input(shape=input_shape_3d)\n",
    "input_2d = Input(shape=input_shape_2d)\n",
    "\n",
    "# Encoding\n",
    "latent_3d = encoder_3d(input_3d)\n",
    "latent_2d = encoder_2d(input_2d)\n",
    "\n",
    "# Concatenate the two latent representations\n",
    "combined_latent = layers.Concatenate()([latent_3d, latent_2d])\n",
    "\n",
    "# Decoding\n",
    "reconstructed_3d = decoder_3d(latent_3d)\n",
    "reconstructed_2d = decoder_2d(latent_2d)\n",
    "\n",
    "# Discriminator outputs\n",
    "disc_output_3d = discriminator_3d(reconstructed_3d)\n",
    "disc_output_2d = discriminator_2d(reconstructed_2d)\n",
    "\n",
    "# Get classification output\n",
    "classification_output = classifier(combined_latent)\n",
    "\n",
    "# Define the combined model\n",
    "model = Model(\n",
    "    inputs=[input_3d, input_2d],\n",
    "    outputs=[\n",
    "        reconstructed_3d,\n",
    "        reconstructed_2d,\n",
    "        disc_output_3d,\n",
    "        disc_output_2d,\n",
    "        classification_output\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fa41a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss weights\n",
    "lambda_reconstruction = 1.0\n",
    "lambda_adversarial = 0.1\n",
    "lambda_classification = 1.0\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'decoder_3d': 'mse',\n",
    "        'decoder_2d': 'mse',\n",
    "        'discriminator_3d': tf.keras.losses.BinaryCrossentropy(),\n",
    "        'discriminator_2d': tf.keras.losses.BinaryCrossentropy(),\n",
    "        'classifier': 'sparse_categorical_crossentropy'\n",
    "    },\n",
    "    loss_weights={\n",
    "        'decoder_3d': lambda_reconstruction,\n",
    "        'decoder_2d': lambda_reconstruction,\n",
    "        'discriminator_3d': lambda_adversarial,\n",
    "        'discriminator_2d': lambda_adversarial,\n",
    "        'classifier': lambda_classification\n",
    "    },\n",
    "    metrics={\n",
    "        'classifier': 'accuracy'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2bceba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "\n",
    "# Discriminator labels (real images are labeled as 1)\n",
    "real_labels = np.ones((struct_features.shape[0], 1))\n",
    "fake_labels = np.zeros((struct_features.shape[0], 1))\n",
    "\n",
    "# For simplicity, use real labels for reconstructed images (you can adjust as needed)\n",
    "disc_targets_3d = real_labels\n",
    "disc_targets_2d = real_labels\n",
    "\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71fb2286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 19:45:46.300200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2024-12-07 19:45:48.131531: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x71c52c098b30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-07 19:45:48.131595: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2024-12-07 19:45:48.153223: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-07 19:45:48.291182: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 17s 578ms/step - loss: 4.8187 - decoder_3d_loss: 0.1945 - decoder_2d_loss: 0.0659 - discriminator_3d_loss: 0.0803 - discriminator_2d_loss: 0.0607 - classifier_loss: 4.5272 - classifier_accuracy: 0.3299 - val_loss: 4.3283 - val_decoder_3d_loss: 0.1922 - val_decoder_2d_loss: 0.0560 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 1.3922e-18 - val_classifier_loss: 4.0562 - val_classifier_accuracy: 0.4800 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 2s 175ms/step - loss: 2.7325 - decoder_3d_loss: 0.1617 - decoder_2d_loss: 0.0506 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 1.6636e-19 - classifier_loss: 2.4919 - classifier_accuracy: 0.3918 - val_loss: 1.7692 - val_decoder_3d_loss: 0.0862 - val_decoder_2d_loss: 0.0499 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 2.4431e-22 - val_classifier_loss: 1.6001 - val_classifier_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 2s 178ms/step - loss: 1.6219 - decoder_3d_loss: 0.0820 - decoder_2d_loss: 0.0596 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 8.1111e-23 - classifier_loss: 1.4448 - classifier_accuracy: 0.2474 - val_loss: 1.3814 - val_decoder_3d_loss: 0.0813 - val_decoder_2d_loss: 0.0549 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 1.7878e-26 - val_classifier_loss: 1.2069 - val_classifier_accuracy: 0.3200 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 2s 177ms/step - loss: 1.3951 - decoder_3d_loss: 0.0659 - decoder_2d_loss: 0.0507 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 5.8196e-27 - classifier_loss: 1.2387 - classifier_accuracy: 0.4330 - val_loss: 1.2073 - val_decoder_3d_loss: 0.0565 - val_decoder_2d_loss: 0.0435 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 2.6361e-26 - val_classifier_loss: 1.0662 - val_classifier_accuracy: 0.4800 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 1.4517 - decoder_3d_loss: 0.0521 - decoder_2d_loss: 0.0429 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 8.5220e-24 - classifier_loss: 1.3150 - classifier_accuracy: 0.3814 - val_loss: 1.1750 - val_decoder_3d_loss: 0.0475 - val_decoder_2d_loss: 0.0369 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 1.4983e-23 - val_classifier_loss: 1.0483 - val_classifier_accuracy: 0.4400 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 2s 173ms/step - loss: 1.2002 - decoder_3d_loss: 0.0426 - decoder_2d_loss: 0.0419 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 3.0125e-23 - classifier_loss: 1.0730 - classifier_accuracy: 0.4227 - val_loss: 1.1951 - val_decoder_3d_loss: 0.0392 - val_decoder_2d_loss: 0.0505 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 7.6003e-25 - val_classifier_loss: 1.0624 - val_classifier_accuracy: 0.4400 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 2s 170ms/step - loss: 1.2949 - decoder_3d_loss: 0.0402 - decoder_2d_loss: 0.0452 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 1.6837e-22 - classifier_loss: 1.1662 - classifier_accuracy: 0.3918 - val_loss: 1.2535 - val_decoder_3d_loss: 0.0458 - val_decoder_2d_loss: 0.0397 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 1.1799e-27 - val_classifier_loss: 1.1244 - val_classifier_accuracy: 0.2400 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 1.2161 - decoder_3d_loss: 0.0379 - decoder_2d_loss: 0.0362 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 2.0310e-19 - classifier_loss: 1.0982 - classifier_accuracy: 0.4021 - val_loss: 1.2337 - val_decoder_3d_loss: 0.0325 - val_decoder_2d_loss: 0.0327 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 2.9004e-21 - val_classifier_loss: 1.1244 - val_classifier_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 2s 177ms/step - loss: 1.1419 - decoder_3d_loss: 0.0310 - decoder_2d_loss: 0.0317 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 7.7722e-15 - classifier_loss: 1.0350 - classifier_accuracy: 0.4742 - val_loss: 1.1023 - val_decoder_3d_loss: 0.0301 - val_decoder_2d_loss: 0.0358 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 7.6064e-17 - val_classifier_loss: 0.9920 - val_classifier_accuracy: 0.5200 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 1.0783 - decoder_3d_loss: 0.0287 - decoder_2d_loss: 0.0309 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 1.5417e-15 - classifier_loss: 0.9743 - classifier_accuracy: 0.5052 - val_loss: 1.1572 - val_decoder_3d_loss: 0.0298 - val_decoder_2d_loss: 0.0317 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 9.8856e-22 - val_classifier_loss: 1.0513 - val_classifier_accuracy: 0.5600 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 3s 224ms/step - loss: 1.0059 - decoder_3d_loss: 0.0286 - decoder_2d_loss: 0.0318 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 2.6871e-17 - classifier_loss: 0.9009 - classifier_accuracy: 0.5670 - val_loss: 1.0813 - val_decoder_3d_loss: 0.0292 - val_decoder_2d_loss: 0.0319 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 1.1644e-19 - val_classifier_loss: 0.9755 - val_classifier_accuracy: 0.6000 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 2s 180ms/step - loss: 0.8933 - decoder_3d_loss: 0.0270 - decoder_2d_loss: 0.0292 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 5.8210e-19 - classifier_loss: 0.7924 - classifier_accuracy: 0.6598 - val_loss: 1.0685 - val_decoder_3d_loss: 0.0292 - val_decoder_2d_loss: 0.0321 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 2.0015e-18 - val_classifier_loss: 0.9622 - val_classifier_accuracy: 0.4400 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 2s 190ms/step - loss: 0.9390 - decoder_3d_loss: 0.0284 - decoder_2d_loss: 0.0294 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 5.4150e-16 - classifier_loss: 0.8360 - classifier_accuracy: 0.6495 - val_loss: 1.1442 - val_decoder_3d_loss: 0.0262 - val_decoder_2d_loss: 0.0300 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 8.2445e-23 - val_classifier_loss: 1.0427 - val_classifier_accuracy: 0.5200 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 3s 198ms/step - loss: 0.7844 - decoder_3d_loss: 0.0262 - decoder_2d_loss: 0.0273 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 3.6637e-16 - classifier_loss: 0.6854 - classifier_accuracy: 0.6495 - val_loss: 1.0714 - val_decoder_3d_loss: 0.0268 - val_decoder_2d_loss: 0.0295 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 2.7362e-18 - val_classifier_loss: 0.9694 - val_classifier_accuracy: 0.6400 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 2s 178ms/step - loss: 0.6898 - decoder_3d_loss: 0.0257 - decoder_2d_loss: 0.0277 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 7.7591e-16 - classifier_loss: 0.5905 - classifier_accuracy: 0.7216 - val_loss: 1.0958 - val_decoder_3d_loss: 0.0251 - val_decoder_2d_loss: 0.0298 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 1.7351e-22 - val_classifier_loss: 0.9947 - val_classifier_accuracy: 0.6400 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 3s 221ms/step - loss: 0.5427 - decoder_3d_loss: 0.0252 - decoder_2d_loss: 0.0275 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 4.2993e-22 - classifier_loss: 0.4437 - classifier_accuracy: 0.8660 - val_loss: 1.0804 - val_decoder_3d_loss: 0.0246 - val_decoder_2d_loss: 0.0289 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 2.9813e-21 - val_classifier_loss: 0.9806 - val_classifier_accuracy: 0.6000 - lr: 2.5000e-04\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 3s 232ms/step - loss: 0.4857 - decoder_3d_loss: 0.0250 - decoder_2d_loss: 0.0253 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 1.1602e-14 - classifier_loss: 0.3890 - classifier_accuracy: 0.8660 - val_loss: 1.0637 - val_decoder_3d_loss: 0.0246 - val_decoder_2d_loss: 0.0294 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 1.6750e-17 - val_classifier_loss: 0.9631 - val_classifier_accuracy: 0.6000 - lr: 2.5000e-04\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.4672 - decoder_3d_loss: 0.0247 - decoder_2d_loss: 0.0245 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 1.7096e-16 - classifier_loss: 0.3713 - classifier_accuracy: 0.8969 - val_loss: 1.1270 - val_decoder_3d_loss: 0.0263 - val_decoder_2d_loss: 0.0286 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 5.0959e-19 - val_classifier_loss: 1.0254 - val_classifier_accuracy: 0.6400 - lr: 2.5000e-04\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 2s 175ms/step - loss: 0.3742 - decoder_3d_loss: 0.0261 - decoder_2d_loss: 0.0242 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 3.2679e-17 - classifier_loss: 0.2772 - classifier_accuracy: 0.9381 - val_loss: 1.2153 - val_decoder_3d_loss: 0.0257 - val_decoder_2d_loss: 0.0285 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 3.1305e-19 - val_classifier_loss: 1.1141 - val_classifier_accuracy: 0.6400 - lr: 2.5000e-04\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.3606 - decoder_3d_loss: 0.0245 - decoder_2d_loss: 0.0235 - discriminator_3d_loss: 0.0000e+00 - discriminator_2d_loss: 2.7105e-17 - classifier_loss: 0.2656 - classifier_accuracy: 0.9381 - val_loss: 1.2109 - val_decoder_3d_loss: 0.0239 - val_decoder_2d_loss: 0.0287 - val_discriminator_3d_loss: 0.0000e+00 - val_discriminator_2d_loss: 9.1565e-19 - val_classifier_loss: 1.1113 - val_classifier_accuracy: 0.6400 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train_3d, X_train_2d],\n",
    "    {\n",
    "        'decoder_3d': X_train_3d,\n",
    "        'decoder_2d': X_train_2d,\n",
    "        'discriminator_3d': disc_targets_3d_train,\n",
    "        'discriminator_2d': disc_targets_2d_train,\n",
    "        'classifier': y_train\n",
    "    },\n",
    "    epochs=20,\n",
    "    batch_size=8,\n",
    "    validation_data=(\n",
    "        [X_test_3d, X_test_2d],\n",
    "        {\n",
    "            'decoder_3d': X_test_3d,\n",
    "            'decoder_2d': X_test_2d,\n",
    "            'discriminator_3d': disc_targets_3d_test,\n",
    "            'discriminator_2d': disc_targets_2d_test,\n",
    "            'classifier': y_test\n",
    "        }\n",
    "    ),\n",
    "    # class_weight=class_weights,\n",
    "    callbacks=[lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a84aa083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Test Accuracy: 64.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier accuracy on the test set\n",
    "evaluation = model.evaluate(\n",
    "    [X_test_3d, X_test_2d],\n",
    "    {\n",
    "        'decoder_3d': X_test_3d,\n",
    "        'decoder_2d': X_test_2d,\n",
    "        'discriminator_3d': disc_targets_3d_test,\n",
    "        'discriminator_2d': disc_targets_2d_test,\n",
    "        'classifier': y_test\n",
    "    },\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Get the index of the classification loss and accuracy (depends on the order of outputs)\n",
    "classification_accuracy = evaluation[model.metrics_names.index('classifier_accuracy')]\n",
    "\n",
    "print(f'Classifier Test Accuracy: {classification_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bf5dcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Train Accuracy : 95.88\n"
     ]
    }
   ],
   "source": [
    "evaluation_train = model.evaluate(\n",
    "    [X_train_3d, X_train_2d],\n",
    "    {\n",
    "        'decoder_3d': X_train_3d,\n",
    "        'decoder_2d': X_train_2d,\n",
    "        'discriminator_3d': disc_targets_3d_train,\n",
    "        'discriminator_2d': disc_targets_2d_train,\n",
    "        'classifier': y_train\n",
    "    },\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "classification_accuracy = evaluation_train[model.metrics_names.index('classifier_accuracy')]\n",
    "\n",
    "print(f'Classifier Train Accuracy : {classification_accuracy * 100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f872430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73cd664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tripti/miniconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] Can't close file (file write failed: time = Thu Nov 28 18:09:47 2024\n, filename = 'models/fusion_model_1.h5', file descriptor = 84, errno = 28, error message = 'No space left on device', buf = 0xbfd3120, total write size = 47824, bytes this sub-write = 47824, bytes actually written = 18446744073709551615, offset = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/fusion_model_1.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/h5py/_hl/files.py:581\u001b[0m, in \u001b[0;36mFile.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mvalid:\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# We have to explicitly murder all open objects related to the file\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \n\u001b[1;32m    578\u001b[0m     \u001b[38;5;66;03m# Close file-resident objects first, then the files.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;66;03m# Otherwise we get errors in MPI mode.\u001b[39;00m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39m_close_open_objects(h5f\u001b[38;5;241m.\u001b[39mOBJ_LOCAL \u001b[38;5;241m|\u001b[39m \u001b[38;5;241m~\u001b[39mh5f\u001b[38;5;241m.\u001b[39mOBJ_FILE)\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39m_close_open_objects(h5f\u001b[38;5;241m.\u001b[39mOBJ_LOCAL \u001b[38;5;241m|\u001b[39m h5f\u001b[38;5;241m.\u001b[39mOBJ_FILE)\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    584\u001b[0m     _objects\u001b[38;5;241m.\u001b[39mnonlocal_close()\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:355\u001b[0m, in \u001b[0;36mh5py.h5f.FileID._close_open_objects\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] Can't close file (file write failed: time = Thu Nov 28 18:09:47 2024\n, filename = 'models/fusion_model_1.h5', file descriptor = 84, errno = 28, error message = 'No space left on device', buf = 0xbfd3120, total write size = 47824, bytes this sub-write = 47824, bytes actually written = 18446744073709551615, offset = 0)"
     ]
    }
   ],
   "source": [
    "model.save(\"models/fusion_model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "603237ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97, 169, 205, 169), (25, 116, 116, 1))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_3d.shape, X_test_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b635c8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names = ['MCI', 'AD', 'CN']\n",
    "\n",
    "# Predict the labels for the test set using the classifier part of your model\n",
    "y_pred_probs = model.predict([X_train_3d, X_train_2d], verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs[4], axis=-1)  # assuming classifier output is in the last dimension\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0712d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.16938663e-01, 3.52988653e-02, 4.77625392e-02],\n",
       "       [2.44880226e-02, 1.30234903e-03, 9.74209607e-01],\n",
       "       [2.57949889e-01, 1.08489856e-01, 6.33560300e-01],\n",
       "       [9.94616807e-01, 3.97935649e-03, 1.40383479e-03],\n",
       "       [1.04013219e-01, 2.44539790e-02, 8.71532798e-01],\n",
       "       [9.11501944e-01, 8.54376145e-03, 7.99542218e-02],\n",
       "       [6.95240557e-01, 2.26158779e-02, 2.82143503e-01],\n",
       "       [8.72728508e-03, 9.89578187e-01, 1.69443851e-03],\n",
       "       [8.56403172e-01, 1.31570056e-01, 1.20267635e-02],\n",
       "       [8.92379284e-02, 5.64928586e-03, 9.05112803e-01],\n",
       "       [1.76591545e-01, 7.91103542e-01, 3.23048905e-02],\n",
       "       [1.51706919e-01, 8.44807506e-01, 3.48564214e-03],\n",
       "       [9.96385336e-01, 2.55420618e-03, 1.06041541e-03],\n",
       "       [3.70892044e-03, 9.96122658e-01, 1.68418454e-04],\n",
       "       [1.50781181e-02, 9.83923137e-01, 9.98779666e-04],\n",
       "       [7.21028805e-01, 2.78501689e-01, 4.69471270e-04],\n",
       "       [9.99754608e-01, 5.57318162e-05, 1.89584403e-04],\n",
       "       [9.61203218e-01, 3.64660770e-02, 2.33059283e-03],\n",
       "       [1.26142148e-03, 9.98621106e-01, 1.17527357e-04],\n",
       "       [8.17524135e-01, 1.80687532e-01, 1.78831909e-03],\n",
       "       [6.50960719e-03, 5.94472652e-03, 9.87545669e-01],\n",
       "       [4.55842637e-05, 2.74838413e-07, 9.99954104e-01],\n",
       "       [8.35997522e-01, 2.73818485e-02, 1.36620641e-01],\n",
       "       [1.84315771e-01, 7.99298942e-01, 1.63852815e-02],\n",
       "       [2.35822815e-02, 9.74495351e-01, 1.92239170e-03],\n",
       "       [4.18783247e-01, 5.21112144e-01, 6.01046495e-02],\n",
       "       [9.03796673e-01, 8.65922496e-02, 9.61108040e-03],\n",
       "       [9.52154875e-01, 4.60661054e-02, 1.77909853e-03],\n",
       "       [8.82685900e-01, 1.14181690e-01, 3.13240569e-03],\n",
       "       [1.91955626e-01, 7.87762880e-01, 2.02814136e-02],\n",
       "       [9.97177362e-01, 2.61705578e-03, 2.05505858e-04],\n",
       "       [1.66864738e-01, 8.24236155e-01, 8.89910944e-03],\n",
       "       [6.76452637e-01, 2.22183447e-02, 3.01329017e-01],\n",
       "       [8.16642940e-01, 2.94758566e-03, 1.80409387e-01],\n",
       "       [1.29756153e-01, 8.64418447e-01, 5.82531700e-03],\n",
       "       [1.04875460e-01, 8.77121270e-01, 1.80033371e-02],\n",
       "       [2.38757022e-02, 9.65651870e-01, 1.04724178e-02],\n",
       "       [8.09662819e-01, 1.00147657e-01, 9.01894867e-02],\n",
       "       [9.25084889e-01, 6.10057525e-02, 1.39092905e-02],\n",
       "       [1.29779344e-02, 3.50546412e-04, 9.86671507e-01],\n",
       "       [9.71816182e-02, 1.20337894e-02, 8.90784621e-01],\n",
       "       [6.88383877e-01, 2.22944319e-01, 8.86718482e-02],\n",
       "       [9.15175736e-01, 5.85418381e-03, 7.89701268e-02],\n",
       "       [8.30036029e-02, 8.92615795e-01, 2.43805666e-02],\n",
       "       [9.02872741e-01, 6.63460940e-02, 3.07811331e-02],\n",
       "       [4.22837436e-01, 4.78433609e-01, 9.87289101e-02],\n",
       "       [8.78906488e-01, 5.84311225e-03, 1.15250334e-01],\n",
       "       [5.85698299e-02, 7.28728808e-03, 9.34142888e-01],\n",
       "       [7.40854025e-01, 2.15400070e-01, 4.37459089e-02],\n",
       "       [3.27474275e-03, 9.96652186e-01, 7.31154942e-05],\n",
       "       [2.57033613e-02, 6.00071438e-03, 9.68295932e-01],\n",
       "       [1.18270144e-01, 1.58586055e-02, 8.65871191e-01],\n",
       "       [1.53989252e-02, 9.84554708e-01, 4.64110963e-05],\n",
       "       [9.99535918e-01, 4.40422853e-04, 2.36964497e-05],\n",
       "       [1.81282090e-03, 9.97915328e-01, 2.71832483e-04],\n",
       "       [9.95714962e-01, 3.88607453e-03, 3.98989621e-04],\n",
       "       [3.61090861e-02, 5.11488132e-03, 9.58776057e-01],\n",
       "       [5.03918603e-02, 9.48974192e-01, 6.33986318e-04],\n",
       "       [3.34666222e-02, 4.35988642e-02, 9.22934532e-01],\n",
       "       [2.43590586e-02, 9.73520398e-01, 2.12050928e-03],\n",
       "       [1.38404831e-01, 2.16961536e-03, 8.59425545e-01],\n",
       "       [9.77065444e-01, 4.52657323e-03, 1.84080061e-02],\n",
       "       [2.32037250e-02, 9.76331592e-01, 4.64633515e-04],\n",
       "       [7.80044436e-01, 2.02188924e-01, 1.77666415e-02],\n",
       "       [5.09232357e-02, 8.42548072e-01, 1.06528714e-01],\n",
       "       [1.54274449e-01, 1.24637065e-02, 8.33261847e-01],\n",
       "       [1.20113716e-02, 9.87344563e-01, 6.44082495e-04],\n",
       "       [4.97893363e-01, 4.94952321e-01, 7.15441257e-03],\n",
       "       [9.13854122e-01, 5.06859533e-02, 3.54599319e-02],\n",
       "       [3.12417775e-01, 2.31337413e-01, 4.56244797e-01],\n",
       "       [2.03332137e-02, 9.61826444e-01, 1.78402811e-02],\n",
       "       [1.09132364e-01, 8.78960371e-01, 1.19072227e-02],\n",
       "       [3.08686551e-02, 8.58489331e-03, 9.60546494e-01],\n",
       "       [9.77260292e-01, 1.35453744e-02, 9.19424836e-03],\n",
       "       [7.92554140e-01, 2.06334427e-01, 1.11136469e-03],\n",
       "       [2.34874189e-01, 5.13311848e-02, 7.13794589e-01],\n",
       "       [9.19666886e-01, 1.28262928e-02, 6.75068274e-02],\n",
       "       [1.54760271e-01, 8.35265756e-01, 9.97394789e-03],\n",
       "       [6.02475464e-01, 3.40642422e-01, 5.68821430e-02],\n",
       "       [9.99361813e-01, 5.12846804e-04, 1.25308594e-04],\n",
       "       [2.92161793e-01, 7.00731218e-01, 7.10696727e-03],\n",
       "       [1.99169889e-01, 2.33850013e-02, 7.77445138e-01],\n",
       "       [2.10532714e-02, 6.56885142e-03, 9.72377896e-01],\n",
       "       [5.07359765e-02, 9.31117535e-01, 1.81464646e-02],\n",
       "       [5.76310232e-02, 3.34667042e-03, 9.39022243e-01],\n",
       "       [3.04145576e-03, 9.92702246e-01, 4.25634626e-03],\n",
       "       [3.57667240e-03, 9.95970607e-01, 4.52762208e-04],\n",
       "       [2.27257982e-01, 7.66005695e-01, 6.73627434e-03],\n",
       "       [4.37028985e-03, 5.27204620e-03, 9.90357697e-01],\n",
       "       [9.82829630e-01, 1.18690226e-02, 5.30132372e-03],\n",
       "       [6.56244159e-02, 9.25901771e-01, 8.47381353e-03],\n",
       "       [1.66502237e-01, 8.32902789e-01, 5.94957033e-04],\n",
       "       [5.37823979e-03, 2.98540317e-03, 9.91636336e-01],\n",
       "       [9.17630672e-01, 6.81256652e-02, 1.42436884e-02],\n",
       "       [4.84482124e-02, 4.78752842e-03, 9.46764290e-01],\n",
       "       [9.90366817e-01, 5.23645431e-03, 4.39670449e-03],\n",
       "       [1.13648765e-01, 2.17572600e-02, 8.64593983e-01]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a36e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
