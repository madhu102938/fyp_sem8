{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "funct_features = np.random.rand(15, 116, 116, 1)\n",
    "struct_features = np.random.rand(15, 256, 256, 256, 1)\n",
    "labels = np.array([0]*5 + [1]*5 + [2]*5) \n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into training and testing sets\n",
    "X_train_3d, X_test_3d, X_train_2d, X_test_2d, y_train, y_test = train_test_split(\n",
    "    struct_features,\n",
    "    funct_features,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "# Discriminator labels (real images are labeled as 1)\n",
    "real_labels_train = np.ones((X_train_3d.shape[0], 1))\n",
    "real_labels_test = np.ones((X_test_3d.shape[0], 1))\n",
    "\n",
    "# For simplicity, use real labels for reconstructed images\n",
    "disc_targets_3d_train = real_labels_train\n",
    "disc_targets_2d_train = real_labels_train\n",
    "\n",
    "disc_targets_3d_test = real_labels_test\n",
    "disc_targets_2d_test = real_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def conv_block_3d(input_tensor, num_filters):\n",
    "    x = layers.Conv3D(num_filters, (3, 3, 3), padding='valid')(input_tensor)\n",
    "    x = layers.Activation('gelu')(x)\n",
    "    x = layers.Conv3D(num_filters, (3, 3, 3), padding='valid')(x)\n",
    "    x = layers.Activation('gelu')(x)\n",
    "    return x\n",
    "\n",
    "def encoder_block_3d(input_tensor, num_filters):\n",
    "    x = conv_block_3d(input_tensor, num_filters)\n",
    "    p = layers.MaxPooling3D((2, 2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block_3d(input_tensor, concat_tensor, num_filters):\n",
    "    x = layers.Conv3DTranspose(num_filters, (2, 2, 2), strides=(2, 2, 2), padding='valid')(input_tensor)\n",
    "    x = layers.concatenate([x, concat_tensor])\n",
    "    x = conv_block_3d(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_unet_3d(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    s1, p1 = encoder_block_3d(inputs, 32)\n",
    "    s2, p2 = encoder_block_3d(p1, 64)\n",
    "    s3, p3 = encoder_block_3d(p2, 128)\n",
    "    s4, p4 = encoder_block_3d(p3, 256)\n",
    "\n",
    "    # Bridge\n",
    "    b1 = conv_block_3d(p4, 512)\n",
    "\n",
    "    # Decoder\n",
    "    d1 = decoder_block_3d(b1, s4, 256)\n",
    "    d2 = decoder_block_3d(d1, s3, 128)\n",
    "    d3 = decoder_block_3d(d2, s2, 64)\n",
    "    d4 = decoder_block_3d(d3, s1, 32)\n",
    "\n",
    "    # Output\n",
    "    outputs = layers.Conv3D(1, (1, 1, 1), activation='sigmoid')(d4)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def build_encoder_2d(input_shape):\n",
    "    inputs = Input(shape=input_shape)  # 116x116x1\n",
    "    x = layers.Conv2D(32, (3, 3), activation='gelu', padding='valid')(inputs)  # 114x114x32\n",
    "    x = layers.MaxPooling2D((2, 2))(x)  # 57x57x32\n",
    "    x = layers.Conv2D(64, (3, 3), activation='gelu', padding='valid')(x)  # 55x55x64\n",
    "    x = layers.MaxPooling2D((2, 2))(x)  # 27x27x64\n",
    "    x = layers.Conv2D(128, (3, 3), activation='gelu', padding='valid')(x)  # 25x25x128\n",
    "    x = layers.Flatten()(x)\n",
    "    latent = layers.Dense(256, activation='gelu', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "    encoder = Model(inputs, latent, name='encoder_2d')\n",
    "    return encoder\n",
    "\n",
    "def build_decoder_2d(latent_dim, output_shape):\n",
    "    latent_inputs = Input(shape=(latent_dim,))\n",
    "    x = layers.Dense((output_shape[0] // 4) * (output_shape[1] // 4) * 64, activation='gelu')(latent_inputs)\n",
    "    x = layers.Reshape((output_shape[0] // 4, output_shape[1] // 4, 64))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), strides=2, padding='valid', activation='gelu')(x)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), strides=2, padding='valid', activation='gelu')(x)\n",
    "    x = layers.Conv2DTranspose(1, (3, 3), padding='valid', activation='sigmoid')(x)\n",
    "    outputs = layers.Cropping2D(cropping=((2, 3), (2, 3)))(x)\n",
    "    assert outputs.shape[1:-1] == output_shape, f\"Output shape {outputs.shape[1:-1]} does not match expected shape {output_shape}\"\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder_2d')\n",
    "    return decoder\n",
    "\n",
    "def build_discriminator_3d(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = layers.Conv3D(32, (3, 3, 3), activation='gelu')(inputs)\n",
    "    x = layers.MaxPooling3D((2, 2, 2))(x)\n",
    "    x = layers.Conv3D(64, (3, 3, 3), activation='gelu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    discriminator = Model(inputs, outputs, name='discriminator_3d')\n",
    "    return discriminator\n",
    "\n",
    "def build_discriminator_2d(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='gelu')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='gelu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    discriminator = Model(inputs, outputs, name='discriminator_2d')\n",
    "    return discriminator\n",
    "\n",
    "def build_classifier(input_dim, num_classes):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = layers.Dense(256, activation='gelu', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation='gelu', kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    classifier = Model(inputs, outputs, name='classifier')\n",
    "    return classifier\n",
    "\n",
    "# Input shapes\n",
    "input_shape_3d = (169, 205, 169, 1)\n",
    "input_shape_2d = (116, 116, 1)\n",
    "latent_dim = 256\n",
    "num_classes = 3\n",
    "\n",
    "# Build models\n",
    "unet_3d = build_unet_3d(input_shape_3d)\n",
    "encoder_2d = build_encoder_2d(input_shape_2d)\n",
    "decoder_2d = build_decoder_2d(latent_dim, input_shape_2d[:-1])\n",
    "discriminator_3d = build_discriminator_3d(input_shape_3d)\n",
    "discriminator_2d = build_discriminator_2d(input_shape_2d)\n",
    "classifier = build_classifier(latent_dim * 2, num_classes)\n",
    "\n",
    "# Inputs\n",
    "input_3d = Input(shape=input_shape_3d)\n",
    "input_2d = Input(shape=input_shape_2d)\n",
    "\n",
    "# Encoding with U-Net for 3D data\n",
    "reconstructed_3d = unet_3d(input_3d)\n",
    "\n",
    "# Global Average Pooling to get latent representation\n",
    "latent_3d = layers.GlobalAveragePooling3D()(reconstructed_3d)\n",
    "\n",
    "# Encoding for 2D data\n",
    "latent_2d = encoder_2d(input_2d)\n",
    "\n",
    "# Concatenate the two latent representations\n",
    "combined_latent = layers.Concatenate()([latent_3d, latent_2d])\n",
    "\n",
    "# Decoding for 2D data\n",
    "reconstructed_2d = decoder_2d(latent_2d)\n",
    "\n",
    "# Discriminator outputs\n",
    "disc_output_3d = discriminator_3d(reconstructed_3d)\n",
    "disc_output_2d = discriminator_2d(reconstructed_2d)\n",
    "\n",
    "# Classification output\n",
    "classification_output = classifier(combined_latent)\n",
    "\n",
    "# Define the combined model\n",
    "model = Model(\n",
    "    inputs=[input_3d, input_2d],\n",
    "    outputs=[\n",
    "        reconstructed_3d,\n",
    "        reconstructed_2d,\n",
    "        disc_output_3d,\n",
    "        disc_output_2d,\n",
    "        classification_output\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Loss weights\n",
    "lambda_reconstruction = 1.0\n",
    "lambda_adversarial = 0.1\n",
    "lambda_classification = 1.0\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'reconstructed_3d': 'mse',\n",
    "        'reconstructed_2d': 'mse',\n",
    "        'disc_output_3d': 'binary_crossentropy',\n",
    "        'disc_output_2d': 'binary_crossentropy',\n",
    "        'classifier': 'sparse_categorical_crossentropy'\n",
    "    },\n",
    "    loss_weights={\n",
    "        'reconstructed_3d': lambda_reconstruction,\n",
    "        'reconstructed_2d': lambda_reconstruction,\n",
    "        'disc_output_3d': lambda_adversarial,\n",
    "        'disc_output_2d': lambda_adversarial,\n",
    "        'classifier': lambda_classification\n",
    "    },\n",
    "    metrics={\n",
    "        'classifier': 'accuracy'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# Discriminator labels (real images are labeled as 1)\n",
    "real_labels = np.ones((struct_features.shape[0], 1))\n",
    "fake_labels = np.zeros((struct_features.shape[0], 1))\n",
    "\n",
    "# For simplicity, use real labels for reconstructed images (you can adjust as needed)\n",
    "disc_targets_3d_train = real_labels[:len(X_train_3d)]\n",
    "disc_targets_2d_train = real_labels[:len(X_train_2d)]\n",
    "disc_targets_3d_test = real_labels[len(X_train_3d):]\n",
    "disc_targets_2d_test = real_labels[len(X_train_2d):]\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Compute sample weights\n",
    "sample_weights = np.array([class_weights_dict[label] for label in labels])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train_3d, X_train_2d],\n",
    "    {\n",
    "        'reconstructed_3d': X_train_3d,\n",
    "        'reconstructed_2d': X_train_2d,\n",
    "        'disc_output_3d': disc_targets_3d_train,\n",
    "        'disc_output_2d': disc_targets_2d_train,\n",
    "        'classifier': y_train\n",
    "    },\n",
    "    sample_weight={\n",
    "        'classifier': sample_weights[:len(X_train_3d)]\n",
    "    },\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    validation_data=(\n",
    "        [X_test_3d, X_test_2d],\n",
    "        {\n",
    "            'reconstructed_3d': X_test_3d,\n",
    "            'reconstructed_2d': X_test_2d,\n",
    "            'disc_output_3d': disc_targets_3d_test,\n",
    "            'disc_output_2d': disc_targets_2d_test,\n",
    "            'classifier': y_test\n",
    "        }\n",
    "    ),\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluation = model.evaluate(\n",
    "    [X_test_3d, X_test_2d],\n",
    "    {\n",
    "        'reconstructed_3d': X_test_3d,\n",
    "        'reconstructed_2d': X_test_2d,\n",
    "        'disc_output_3d': disc_targets_3d_test,\n",
    "        'disc_output_2d': disc_targets_2d_test,\n",
    "        'classifier': y_test\n",
    "    },\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "classification_accuracy = evaluation[model.metrics_names.index('classifier_accuracy')]\n",
    "\n",
    "print(f'Classifier Test Accuracy: {classification_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"classifier\" (type Functional).\n\nInput 0 of layer \"dense_2\" is incompatible with the layer: expected axis -1 of input shape to have value 512, but received input with shape (None, 257)\n\nCall arguments received by layer \"classifier\" (type Functional):\n  • inputs=tf.Tensor(shape=(None, 257), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m reconstructed_2d \u001b[38;5;241m=\u001b[39m decoder_2d(latent_2d)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Classification output\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m classification_output \u001b[38;5;241m=\u001b[39m classifier(combined_latent)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Define the combined model\u001b[39;00m\n\u001b[0;32m     36\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(\n\u001b[0;32m     37\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[input_3d, input_2d],\n\u001b[0;32m     38\u001b[0m     outputs\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     ]\n\u001b[0;32m     43\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\maddi\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py:280\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    275\u001b[0m             value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape_as_list[\u001b[38;5;28mint\u001b[39m(axis)] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    277\u001b[0m             value,\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    279\u001b[0m         }:\n\u001b[1;32m--> 280\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    282\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m             )\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"classifier\" (type Functional).\n\nInput 0 of layer \"dense_2\" is incompatible with the layer: expected axis -1 of input shape to have value 512, but received input with shape (None, 257)\n\nCall arguments received by layer \"classifier\" (type Functional):\n  • inputs=tf.Tensor(shape=(None, 257), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input shapes\n",
    "input_shape_3d = (256, 256, 256, 1)\n",
    "input_shape_2d = (116, 116, 1)\n",
    "latent_dim = 256\n",
    "num_classes = 3\n",
    "\n",
    "# Build models\n",
    "unet_3d = build_unet_3d(input_shape_3d)\n",
    "encoder_2d = build_encoder_2d(input_shape_2d)\n",
    "decoder_2d = build_decoder_2d(latent_dim, input_shape_2d[:-1])\n",
    "classifier = build_classifier(latent_dim * 2, num_classes)\n",
    "\n",
    "# Inputs\n",
    "input_3d = Input(shape=input_shape_3d)\n",
    "input_2d = Input(shape=input_shape_2d)\n",
    "\n",
    "# Encoding with U-Net for 3D data\n",
    "reconstructed_3d = unet_3d(input_3d)\n",
    "\n",
    "# Global Average Pooling to get latent representation\n",
    "latent_3d = layers.GlobalAveragePooling3D()(reconstructed_3d)\n",
    "\n",
    "# Encoding for 2D data\n",
    "latent_2d = encoder_2d(input_2d)\n",
    "\n",
    "# Concatenate the two latent representations\n",
    "combined_latent = layers.Concatenate()([latent_3d, latent_2d])\n",
    "\n",
    "# Decoding for 2D data\n",
    "reconstructed_2d = decoder_2d(latent_2d)\n",
    "\n",
    "# Classification output\n",
    "classification_output = classifier(combined_latent)\n",
    "\n",
    "# Define the combined model\n",
    "model = Model(\n",
    "    inputs=[input_3d, input_2d],\n",
    "    outputs=[\n",
    "        reconstructed_3d,\n",
    "        reconstructed_2d,\n",
    "        classification_output\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss weights\n",
    "lambda_reconstruction = 1.0\n",
    "lambda_classification = 1.0\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'reconstructed_3d': 'mse',\n",
    "        'reconstructed_2d': 'mse',\n",
    "        'classifier': 'sparse_categorical_crossentropy'\n",
    "    },\n",
    "    loss_weights={\n",
    "        'reconstructed_3d': lambda_reconstruction,\n",
    "        'reconstructed_2d': lambda_reconstruction,\n",
    "        'classifier': lambda_classification\n",
    "    },\n",
    "    metrics={\n",
    "        'classifier': 'accuracy'\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# Discriminator labels (real images are labeled as 1)\n",
    "real_labels = np.ones((struct_features.shape[0], 1))\n",
    "fake_labels = np.zeros((struct_features.shape[0], 1))\n",
    "\n",
    "# For simplicity, use real labels for reconstructed images (you can adjust as needed)\n",
    "disc_targets_3d = real_labels\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Compute sample weights\n",
    "sample_weights = np.array([class_weights_dict[label] for label in labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train_3d, X_train_2d],\n",
    "    {\n",
    "        'reconstructed_3d': X_train_3d,\n",
    "        'reconstructed_2d': X_train_2d,\n",
    "        'classifier': y_train\n",
    "    },\n",
    "    sample_weight={\n",
    "        'classifier': sample_weights\n",
    "    },\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    validation_data=(\n",
    "        [X_test_3d, X_test_2d],\n",
    "        {\n",
    "            'reconstructed_3d': X_test_3d,\n",
    "            'reconstructed_2d': X_test_2d,\n",
    "            'classifier': y_test\n",
    "        }\n",
    "    ),\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "evaluation = model.evaluate(\n",
    "    [X_test_3d, X_test_2d],\n",
    "    {\n",
    "        'reconstructed_3d': X_test_3d,\n",
    "        'reconstructed_2d': X_test_2d,\n",
    "        'classifier': y_test\n",
    "    },\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "classification_accuracy = evaluation[model.metrics_names.index('classifier_accuracy')]\n",
    "\n",
    "print(f'Classifier Test Accuracy: {classification_accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
